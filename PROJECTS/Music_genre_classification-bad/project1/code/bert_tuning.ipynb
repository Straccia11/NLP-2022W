{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn import preprocessing, metrics\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bert_model(bert_enc, bert_prepr, classes_count):\n",
    "    '''\n",
    "    Create model based on BERT.\n",
    "    Parameters:\n",
    "        bert_enc (str): Link to BERT model.\n",
    "        bert_prepr (str): Link to BERT preprocessing.\n",
    "        classes_count (int): Number of classes (genres).\n",
    "    Returns:\n",
    "        Model: Created model.\n",
    "    '''\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "    preprocessing_layer = hub.KerasLayer(bert_prepr, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(bert_enc, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(classes_count, activation='softmax', name='classifier')(net)\n",
    "    model = tf.keras.Model(text_input, net)\n",
    "    \n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_X(data_x):\n",
    "    '''\n",
    "    Transform Series into numpy array.\n",
    "    Parameters:\n",
    "        data_x (Series): Lyrics of the data.\n",
    "    Returns:\n",
    "        ndarray: Array with lyrics.\n",
    "    '''\n",
    "    X = np.array(data_x)\n",
    "    X = np.asarray(X).astype('str')\n",
    "    X = X.reshape(-1,1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bert(data_x, data_y, test_x, test_y, model, label_encoder, dataset_name, epochs=1, model_dir='models', filename='bert_tuned'):\n",
    "    '''\n",
    "    Train a model.\n",
    "    Parameters:\n",
    "        data_x (Series): Lyrics of the training data.\n",
    "        data_y (Series): Genres of the training data.\n",
    "        test_x (Series): Lyrics of the validation/test data.\n",
    "        test_y (Series): Genres of the validation/test data.\n",
    "        model (Model): Created BERT model.\n",
    "        label_encoder (LabelEncoder): Label encoder after fitting.\n",
    "        dataset_name (str): Name of the dataset.\n",
    "        epochs (int): Number of epochs.\n",
    "        model_dir (str): Name of directory for saved models.\n",
    "        filename (str): Part of the saved model file name.\n",
    "    Returns:\n",
    "        History: A History object.\n",
    "    '''\n",
    "    print('Training...')\n",
    "    fname = os.path.join(model_dir, dataset_name, f'model_{filename}')\n",
    "    Y = label_encoder.transform(data_y).reshape(-1,1)\n",
    "    X = transform_X(data_x)\n",
    "    Yt = label_encoder.transform(test_y).reshape(-1,1)\n",
    "    Xt = transform_X(test_x)\n",
    "    history = model.fit(x=X, y=Y, epochs=epochs, validation_data=(Xt, Yt))\n",
    "    model.save(fname)\n",
    "    print('Success!')\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_bert(data_x, model, label_encoder, dataset_name, pred_dir='predictions', filename='bert_tuned'):\n",
    "    '''\n",
    "    Test a model and return predictions.\n",
    "    Parameters:\n",
    "        data_x (Series): Lyrics of the test data.\n",
    "        model (Model): Trained BERT model.\n",
    "        label_encoder (LabelEncoder): Label encoder after fitting.\n",
    "        dataset_name (str): Name of the dataset.\n",
    "        pred_dir (str): Name of directory for saved predictions.\n",
    "        filename (str): Part of the saved predictions file name.\n",
    "    Returns:\n",
    "        ndarray: Predicted genres.\n",
    "    '''\n",
    "    print('Testing...')\n",
    "    fname = os.path.join(pred_dir, dataset_name, f'model_{filename}.csv')\n",
    "    if os.path.exists(fname):\n",
    "        os.remove(fname)\n",
    "    X = transform_X(data_x)\n",
    "    predictions_enc = np.argmax(model.predict(X), axis=1).flatten()\n",
    "    predictions = label_encoder.inverse_transform(predictions_enc)\n",
    "    pd.DataFrame(predictions.reshape(-1, 1)).to_csv(fname, mode='a', index=False, header=False)\n",
    "    print('Success!')\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(y_true, y_pred):\n",
    "    '''\n",
    "    Print accuracy, balanced accuracy and F1 score.\n",
    "    Parameters:\n",
    "        y_true (Series): True genres of the test data.\n",
    "        y_pred (Series): Predicted genres of the test data.\n",
    "    '''\n",
    "    print('RESULTS:')\n",
    "    print(f'accuracy = {metrics.accuracy_score(y_true=y_true, y_pred=y_pred)}')\n",
    "    print(f'balanced accuracy = {metrics.balanced_accuracy_score(y_true=y_true, y_pred=y_pred)}')\n",
    "    print(f'f1 score = {metrics.f1_score(y_true=y_true, y_pred=y_pred, average='weighted')}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "dataset_name = 'small_balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Links to models\n",
    "\n",
    "# bert_en_uncased_L-12_H-768_A-12\n",
    "bert_enc = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\n",
    "bert_prepr = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "# small_bert/bert_en_uncased_L-2_H-256_A-4\n",
    "bert_enc_sm = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1'\n",
    "bert_prepr_sm = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of necessary directories\n",
    "\n",
    "model_dir = os.path.join('models', dataset_name)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "pred_dir = os.path.join('predictions', dataset_name)\n",
    "if not os.path.exists(pred_dir):\n",
    "    os.makedirs(pred_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading training and test data from CSV files\n",
    "\n",
    "train_data = pd.read_csv(f'data/train/{dataset_name}.csv')\n",
    "test_data = pd.read_csv(f'data/test/{dataset_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoder fitting\n",
    "\n",
    "genres = np.unique(train_data.genre)\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(genres)\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of Smaller BERT model\n",
    "\n",
    "bert_model_sm = create_bert_model(bert_enc_sm, bert_prepr_sm, len(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of BERT model\n",
    "\n",
    "bert_model = create_bert_model(bert_enc, bert_prepr, len(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training of Smaller BERT model\n",
    "\n",
    "hist_sm = train_bert(train_data.lyrics, train_data.genre, \n",
    "                     test_data.lyrics, test_data.genre,\n",
    "                     bert_model_sm, label_encoder, dataset_name, epochs=1, filename='small_bert_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing of Smaller BERT model and printing results\n",
    "\n",
    "preds = test_bert(test_data.lyrics, bert_model_sm, label_encoder, dataset_name, filename='small_bert_tuned')\n",
    "get_results(test_data.genre, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training of BERT model\n",
    "\n",
    "hist = train_bert(train_data.lyrics, train_data.genre, \n",
    "                  test_data.lyrics, test_data.genre,\n",
    "                  bert_model, label_encoder, dataset_name, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing of BERT model and printing results\n",
    "\n",
    "preds = test_bert(test_data.lyrics, bert_model, label_encoder, dataset_name)\n",
    "get_results(test_data.genre, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c978efebeb2270acb6188b84252153fa3db86f2d5406301959b558db2528b4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
