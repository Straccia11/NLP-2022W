\section{Approach and research methodology}\label{approach}

\subsection{Datasets}\label{datasets}
While trying to find possible datasets for our project it was important to us for the song lyrics to be in their raw form. That means that they should not be transformed into e.g. bag-of-words model. The reason for this decision was that if we would like to use prepared models in a real-world scenario new song lyrics could be used with minimal preparation. What is more, as the language evolves all the time, with this approach there is still a possibility of further training of the models on song lyrics with the presence of not previously known words. And last but not least, we also wanted to minimize the risk of worse performance of prepared models which could be caused by simplifying the assumptions.

The effect of making this decision is the fact that we could not choose e.g. the musiXmatch dataset (the official lyrics collection of the Million Song Dataset \cite{Bertin-Mahieux2011}) as the dataset for conducting the experiments. This very well-known dataset consists of an enormous number of song lyrics which are unfortunately kept in a bag-of-words model form. But as we do not use this dataset, we also do not focus on its description.

We have found two datasets that meet our expectations:
\begin{itemize}
    \item \textit{Song lyrics from 79 musical genres} dataset from Kaggle website \cite{KaggleDataset},
    \item \textit{MetroLyrics} dataset processed and put in a GitHub repository \cite{GithubDataset}.
\end{itemize}

In the description of the first dataset, we can find the information that the dataset consists of 379 893 song lyrics from 4239 artists. Around 50\% of the song lyrics are in English and we test our models on them. Information about the artists is kept in a separate file and contains a list of music genres each artist is connected with. As we predict only one music genre for each song we preprocess this dataset by reducing these lists to individual genres (we take the first one from the list) and assigning them to song lyrics of appropriate artists. Furthermore, we preprocess song lyrics as they contain punctuation and span across multiple lines.

By contrast, the second dataset required minimal work on our site. It was initially published on Kaggle website and consisted of 362 237 song lyrics from 18231 artists. The majority of song lyrics (probably around 60\%) were in English. Unfortunately, this dataset was removed from Kaggle website and we were not able to find it in its original form anywhere else. We have found a preprocessed version of it in a GitHub repository of a students' project performed by University of California students in 2018. This version's song lyrics have punctuation removed and contain only one genre for each entry.

\subsection{Datasets preparation}\label{Datasets preparation}

First of all, we conducted some basic preparations of datasets.
For \textit{MetroLyrics} we decided to remove genre \textit{Other} and merge genres \textit{Country} and \textit{Folk} since  our research showed they are very similar, and additionally the second was significantly smaller in samples. As for \textit{Song lyrics from 79 musical genres}, we filtered songs to only English ones and omitted the genre \textit{Pop/Rock} since it is ambiguous.

After conducting a few simple tests on the whole dataset we decided to limit ourselves to a much smaller part of the observations. There were two main reasons for that: limited resources and time - we would not manage to conduct all desired tests on the whole dataset, and second - the dataset was very strongly unbalanced and therefore accuracy was often significantly bigger than balanced accuracy. To solve both problems we decided to limit ourselves to only five genres with the biggest number of samples: \textit{Rock}, \textit{Pop}, \textit{Metal}, \textit{Hip-hop} and \textit{Country}.

In the end, we conducted tests on two datasets:
\begin{itemize}
    \item Balanced dataset with lyrics from 5 genres, $116,120$ observations in total, created from both \textit{MetroLyrics} and \textit{Song lyrics from 79 musical genres} datasets. The main reason for balancing the dataset was a further decrease in training time and therefore a possibility for testing more methods.

    \item Unbalanced dataset with both lyrics and title from 5 genres, $68,221$ observations in total, created only from \textit{Song lyrics from 79 musical genres} dataset since only this dataset had title available.
\end{itemize}

\subsection{Text preprocessing}

Since in our project we use embeddings that may be or even should be used on the raw text we decided to test two approaches: one with strong and the second with weak preprocessing of text.

Weak preprocessing consists of deleting numbers in the text and some words characteristic of lyrics notation (e.g. "VERSE", "CHORUS", "2x"). We decided to also expand contractions since they were proven to be troublesome in further preprocessing such as tokenization or removing stopwords. We deleted all special characters since interpunction was used inconsistently in most songs (e.g. lyrics usually didn't have a division for sentences). We also lowered the whole text since every verse began with a capital letter which usually had nothing to do with starting a sentence. Thanks to that we could also use uncased versions of embeddings.

Strong preprocessing consists of, besides the above, tokenization, lemmatization, and deleting stop words. For these steps, we used \textit{nltk} package.

\subsection{Embeddings}

One of the key problems in the domain of natural language processing has to be the question of how to use words in a model which only understands numbers. This question sparked numerous attempts of representing language in a mathematical way. One can always assign each unique word a different number and in this way encode any language into the computer, but this is insufficient when it comes to using this encoded representation. It was rather clear, that in order for such transformation to be in any way useful, the original meaning of the word should be embedded into this numeric representation itself. This word embedding ought to be treated as a vector in a given, high-dimensional space. For a given model dimensionality is fixed, therefore each word is represented by a vector of a set length, typically a hundred or so numeric values.

There is still a task of creating a model capable of such transformations. It has a couple of possible approaches, mainly prediction-based and count-based. The second one, although simpler, will not be described here, since all methods described further make use of the first approach. Prediction-based word embedding models share a common trait, which unsurprisingly is that the embedding for a word was learned by performing the task of predicting given word \cite{baroni}. This definition does not set any requirements for the prediction itself, and, in fact, different approaches have been used successfully, such as the continuous Bag-of-Words Model (CBOW) and  continuous Skip-gram Model \cite{mikolov2013}.

There is a single more distinction for the different techniques used, which is significant for this work. The meaning of some words is not dependent on their structure or origin, but on the context in which they are used. In the case of homonyms, it is impossible to state the singular meaning of the word without context, e.g. bank as a financial institution vs. side of a river or play as in theatre vs. as in sport. More traditional embeddings do not incorporate the context of a word in determining its embedding. These models are called static or non-contextualized. The ones that do generate differentiable vectors depending on the context are subcategorized as contextualized word embeddings. Despite the described advantage of the latter method, prior has proven to be successful in multiple cases, such as GloVe \cite{glove} or fastText \cite{fastText}.

Other techniques which prove promising are ELMo \cite{elmo}, a deep bidirectional language model, which is pre-trained on a large text corpus and, extracting contextualized word embedding form, pre-trained Googleâ€™s Bidirectional Encoder Representations from Transformers (BERT) \cite{bert}. 

Little has been said about using word embedding in the context of music lyrics. \cite{musicWordEmbed} describes the process of training the word embedding model strictly on music lyrics, but lacks proper evaluation methods to be comparable to other works. This means that in order to reach state-of-the-art we were bound to testing various methods of word embedding. We decided to test GloVe, word2vec and BERT. In order to do that we use the nlu library from John Snow Labs \cite{nlu}.

\subsection{Classification models}

We test a few varying classification models for this specific task. We consider Naive Bayes classifier, Linear Support Vector Machine, XGBoost, and Convolutional Neural Network.

Naive Bayes is a classifier based on Bayes' theorem known for good performance on real-world tasks despite being a simple model. It is fast and good at dealing with unbalanced data. It has also widespread applications on text classification tasks \cite{naiveBayesRef}.

Linear Support Vector Machine tries to find a hyperplane that best separates samples of different classes. It is often used for text classification tasks and historically achieved great results \cite{svmRef}.

XGBoost \cite{xgboostRef} is a decision-tree based algorithm that uses a gradient boosting method. It shows great performance on large-scale tasks and is a very flexible and versatile tool.

Convolutional Neural Networks are one of the primarily used types of neural networks used commonly in both image and text classification \cite{cnnRef}. Their main feature is using layers with convolution filters that are applied to feature vectors.

\subsection{Adding title to song lyrics}\label{title}
When it comes to the additional approach that we tried, i.e. adding title to the song lyrics, it can be described in the following way. Normally we would input the song lyrics into the embedding model and then provide the output to the classifier. Instead, we independently produce the embeddings of the lyrics and the title and combine these two vectors together by putting the title vector first and the lyrics vector right beside. Then, the resulting vector is inserted to the classifier.

